{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ¯ Model 2: Modified Convolution Model (Stride = 1)\n",
    "\n",
    "Based on **Generative Deep Learning (2nd Edition)**, Chapter 2 - Convolutions\n",
    "\n",
    "This notebook implements Model 2: a modified version with stride = 1. This model is identical to Model 1 in architecture but explicitly uses stride = 1 for the convolution layer to demonstrate the effect of stride on feature maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kalirajannatarajan/projects/models-activation-comparison/venv/lib/python3.11/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare the Dataset\n",
    "\n",
    "Using MNIST dataset (handwritten digits) - same as Model 1. Images are 28x28 grayscale, 10 classes (digits 0-9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING DATASET\n",
      "======================================================================\n",
      "Training data shape: (60000, 28, 28, 1)\n",
      "Test data shape: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "print(\"=\" * 70)\n",
    "print(\"LOADING DATASET\")\n",
    "print(\"=\" * 70)\n",
    "(x_train_full, y_train_full), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to [0, 1] range for better training stability\n",
    "x_train_full = x_train_full.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Expand dimensions to add channel axis: (60000, 28, 28) -> (60000, 28, 28, 1)\n",
    "# Conv2D layers require input shape: (height, width, channels)\n",
    "x_train_full = np.expand_dims(x_train_full, axis=-1)\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "print(f\"Training data shape: {x_train_full.shape}\")\n",
    "print(f\"Test data shape: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train / Validation Split\n",
    "\n",
    "Same split as Model 1: 50,000 samples for training, 10,000 for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set: 50000 samples\n",
      "Validation set: 10000 samples\n",
      "Test set: 10000 samples\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val = x_train_full[:50000], x_train_full[50000:]\n",
    "y_train, y_val = y_train_full[:50000], y_train_full[50000:]\n",
    "\n",
    "print(f\"\\nTrain set: {x_train.shape[0]} samples\")\n",
    "print(f\"Validation set: {x_val.shape[0]} samples\")\n",
    "print(f\"Test set: {x_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build the Modified Convolution Model (Stride = 1)\n",
    "\n",
    "**KEY MODIFICATION: stride = (1, 1)**\n",
    "\n",
    "- Stride = 1 means the filter moves 1 pixel at a time in both directions\n",
    "- This preserves maximum spatial information from the input\n",
    "- With stride = 1 and valid padding, the output feature map size is: `output_size = (input_size - kernel_size + 1) / stride`\n",
    "- For 28x28 input with 3x3 kernel: (28 - 3 + 1) / 1 = 26x26\n",
    "\n",
    "**Why stride = 1 preserves more spatial information:**\n",
    "- The filter examines every possible position in the input image\n",
    "- No information is skipped between positions\n",
    "- This results in a larger feature map (26x26) compared to stride = 2 (13x13)\n",
    "- More spatial detail is retained, which can help with fine-grained features\n",
    "\n",
    "**Comparison to Model 1:**\n",
    "- Model 1 also used stride = 1, so this model is architecturally identical\n",
    "- However, explicitly setting stride = 1 demonstrates the baseline case\n",
    "- If stride were 2, the feature map would be 13x13, losing spatial resolution\n",
    "- Stride = 1 is optimal for preserving spatial relationships in images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BUILDING MODEL 2: MODIFIED CONVOLUTION (STRIDE = 1)\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kalirajannatarajan/projects/models-activation-comparison/venv/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"BUILDING MODEL 2: MODIFIED CONVOLUTION (STRIDE = 1)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# Input layer (Keras 3.x recommended approach to avoid warnings)\n",
    "model.add(layers.Input(shape=(28, 28, 1)))\n",
    "\n",
    "# Convolution layer with stride = 1 (explicitly set)\n",
    "model.add(layers.Conv2D(filters=32,\n",
    "                        kernel_size=(3, 3),\n",
    "                        strides=(1, 1),  # EXPLICITLY SET TO 1\n",
    "                        padding='valid',\n",
    "                        activation='relu'))\n",
    "\n",
    "# Flatten the 2D feature maps into a 1D vector for dense layers\n",
    "# Output from Conv2D: (batch, 26, 26, 32) -> Flatten -> (batch, 26*26*32)\n",
    "# With stride = 1, we get 26x26 = 676 spatial positions per filter\n",
    "# Total flattened size: 26 * 26 * 32 = 21,632 features\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Dense (fully connected) layer for feature combination\n",
    "# 32 units: same as Model 1 for direct comparison\n",
    "model.add(layers.Dense(units=32, activation='relu'))\n",
    "\n",
    "# Output layer: 10 units for 10 digit classes, softmax for probability distribution\n",
    "model.add(layers.Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compile the Model\n",
    "\n",
    "Same optimizer and loss as Model 1 for direct comparison. Using RMSprop optimizer and sparse categorical crossentropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m.compile(optimizer=optimizers.RMSprop(),\n\u001b[32m      2\u001b[39m               loss=\u001b[33m'\u001b[39m\u001b[33msparse_categorical_crossentropy\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      3\u001b[39m               metrics=[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizers.RMSprop(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Summary and Convolution Layer Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MODEL SUMMARY\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMODEL SUMMARY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mmodel\u001b[49m.summary()\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Extract and display convolution layer configuration\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"MODEL SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "model.summary()\n",
    "\n",
    "# Extract and display convolution layer configuration\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CONVOLUTION LAYER CONFIGURATION\")\n",
    "print(\"=\" * 70)\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, layers.Conv2D):\n",
    "        print(f\"Layer Name: {layer.name}\")\n",
    "        print(f\"  Filters: {layer.filters}\")\n",
    "        print(f\"  Kernel Size: {layer.kernel_size}\")\n",
    "        print(f\"  Strides: {layer.strides}  <-- EXPLICITLY SET TO (1, 1)\")\n",
    "        print(f\"  Padding: {layer.padding}\")\n",
    "        # Get activation name safely\n",
    "        if hasattr(layer.activation, '__name__'):\n",
    "            activation_name = layer.activation.__name__\n",
    "        elif callable(layer.activation):\n",
    "            activation_name = str(layer.activation)\n",
    "        else:\n",
    "            activation_name = str(layer.activation)\n",
    "        print(f\"  Activation: {activation_name}\")\n",
    "        print(f\"  Input Shape: (28, 28, 1)\")\n",
    "        print(f\"  Output Shape: (26, 26, 32)  [28-3+1=26 with stride=1, valid padding, 32 filters]\")\n",
    "        print(f\"\\n  NOTE: Stride = 1 means the filter examines every pixel position,\")\n",
    "        print(f\"        preserving maximum spatial information in the feature map.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train the Model\n",
    "\n",
    "Training with 5 epochs, batch size 64, RMSprop optimizer, and sparse categorical crossentropy loss. **Key modification: Convolution Stride = (1, 1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"TRAINING MODEL 2: MODIFIED CONVOLUTION (STRIDE = 1)\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Training with the following settings:\")\n",
    "print(\"  - Epochs: 5\")\n",
    "print(\"  - Batch Size: 64\")\n",
    "print(\"  - Optimizer: RMSprop\")\n",
    "print(\"  - Loss: Sparse Categorical Crossentropy\")\n",
    "print(\"  - Convolution Stride: (1, 1)  <-- KEY MODIFICATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=5,\n",
    "                    batch_size=64,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)\n",
    "\n",
    "# Extract final training and validation accuracies\n",
    "final_train_acc = history.history['accuracy'][-1]\n",
    "final_val_acc = history.history['val_accuracy'][-1]\n",
    "\n",
    "# Print per-epoch accuracies\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TRAINING HISTORY - ACCURACY PER EPOCH\")\n",
    "print(\"=\" * 70)\n",
    "for epoch in range(len(history.history['accuracy'])):\n",
    "    print(f\"Epoch {epoch + 1}:\")\n",
    "    print(f\"  Training Accuracy:   {history.history['accuracy'][epoch]:.4f}\")\n",
    "    print(f\"  Validation Accuracy: {history.history['val_accuracy'][epoch]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"EVALUATING ON TEST SET\")\n",
    "print(\"=\" * 70)\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final Results (Formatted for Academic Submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MODEL 2: MODIFIED CONVOLUTION (STRIDE = 1)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Final Training Accuracy:   {final_train_acc:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {final_val_acc:.4f}\")\n",
    "print(f\"Final Test Accuracy:       {test_acc:.4f}\")\n",
    "print(f\"Final Test Loss:           {test_loss:.4f}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nModel Configuration Summary:\")\n",
    "print(\"  - Architecture: Conv2D -> Flatten -> Dense -> Dense\")\n",
    "print(\"  - Conv2D: 32 filters, 3x3 kernel, stride = (1, 1), valid padding\")\n",
    "print(\"  - Stride = 1 preserves maximum spatial resolution (26x26 feature maps)\")\n",
    "print(\"  - This model is architecturally identical to Model 1\")\n",
    "print(\"  - Stride = 1 allows the filter to examine every pixel position\")\n",
    "print(\"  - No pooling, no batch normalization, minimal architecture\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nComparison Notes:\")\n",
    "print(\"  - Stride = 1 means the convolution filter moves 1 pixel at a time\")\n",
    "print(\"  - This preserves more spatial information than larger strides\")\n",
    "print(\"  - Feature map size: 26x26 (with 3x3 kernel and valid padding)\")\n",
    "print(\"  - If stride were 2, feature map would be 13x13, losing spatial detail\")\n",
    "print(\"  - Stride = 1 is optimal for preserving fine-grained image features\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MLP Activation Comparison)",
   "language": "python",
   "name": "mlp-activation-comparison"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
