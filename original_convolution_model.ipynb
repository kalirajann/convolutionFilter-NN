{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸŽ¯ Model 1: Original Convolution Model (Textbook Version)\n",
        "\n",
        "Based on **Generative Deep Learning (2nd Edition)**, Chapter 2 - Convolutions\n",
        "\n",
        "This notebook implements the ORIGINAL convolution model as a baseline case, demonstrating the fundamental convolution operation with a single Conv2D layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load and Prepare the Dataset\n",
        "\n",
        "Using MNIST dataset (handwritten digits) - standard for baseline CNN models. Images are 28x28 grayscale, 10 classes (digits 0-9)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load MNIST dataset\n",
        "print(\"=\" * 70)\n",
        "print(\"LOADING DATASET\")\n",
        "print(\"=\" * 70)\n",
        "(x_train_full, y_train_full), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to [0, 1] range for better training stability\n",
        "x_train_full = x_train_full.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Expand dimensions to add channel axis: (60000, 28, 28) -> (60000, 28, 28, 1)\n",
        "# Conv2D layers require input shape: (height, width, channels)\n",
        "x_train_full = np.expand_dims(x_train_full, axis=-1)\n",
        "x_test = np.expand_dims(x_test, axis=-1)\n",
        "\n",
        "print(f\"Training data shape: {x_train_full.shape}\")\n",
        "print(f\"Test data shape: {x_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Train / Validation Split\n",
        "\n",
        "Standard split: 50,000 samples for training, 10,000 for validation. This matches common practice in deep learning textbooks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train, x_val = x_train_full[:50000], x_train_full[50000:]\n",
        "y_train, y_val = y_train_full[:50000], y_train_full[50000:]\n",
        "\n",
        "print(f\"\\nTrain set: {x_train.shape[0]} samples\")\n",
        "print(f\"Validation set: {x_val.shape[0]} samples\")\n",
        "print(f\"Test set: {x_test.shape[0]} samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Build the Original Convolution Model\n",
        "\n",
        "The Conv2D layer applies learnable filters (kernels) to detect features in the input image. Each filter performs a sliding window operation.\n",
        "\n",
        "**Key hyperparameters (EXACTLY as in textbook baseline):**\n",
        "- `filters=32`: Number of different feature detectors (32 different patterns)\n",
        "- `kernel_size=(3,3)`: Each filter is 3x3 pixels (matches manual filters in notebook)\n",
        "- `strides=(1,1)`: Filter moves 1 pixel at a time (no skipping)\n",
        "  - Stride affects feature map size: stride=1 keeps size similar to input\n",
        "  - Larger stride (e.g., 2) would skip positions, reducing output size\n",
        "- `padding='valid'`: No zero-padding around edges\n",
        "  - With valid padding and 3x3 kernel, output is 2 pixels smaller per dimension\n",
        "  - Input: 28x28 â†’ Output: 26x26 (28 - 3 + 1 = 26)\n",
        "- `activation='relu'`: ReLU activation introduces non-linearity\n",
        "\n",
        "This represents the **BASELINE case**: simplest possible CNN with one conv layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"BUILDING MODEL\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "# Convolution layer (the core of this baseline model)\n",
        "model.add(layers.Conv2D(filters=32,\n",
        "                        kernel_size=(3, 3),\n",
        "                        strides=(1, 1),\n",
        "                        padding='valid',\n",
        "                        activation='relu',\n",
        "                        input_shape=(28, 28, 1)))\n",
        "\n",
        "# Flatten the 2D feature maps into a 1D vector for dense layers\n",
        "# Output from Conv2D: (batch, 26, 26, 32) -> Flatten -> (batch, 26*26*32)\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# Dense (fully connected) layer for feature combination\n",
        "# 32 units: smaller hidden layer for this baseline model\n",
        "model.add(layers.Dense(units=32, activation='relu'))\n",
        "\n",
        "# Output layer: 10 units for 10 digit classes, softmax for probability distribution\n",
        "model.add(layers.Dense(units=10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Compile the Model\n",
        "\n",
        "Using RMSprop optimizer (common baseline choice). Sparse categorical crossentropy is appropriate for integer labels (0-9)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(optimizer=optimizers.RMSprop(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Summary and Convolution Layer Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"MODEL SUMMARY\")\n",
        "print(\"=\" * 70)\n",
        "model.summary()\n",
        "\n",
        "# Extract and display convolution layer configuration\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"CONVOLUTION LAYER CONFIGURATION\")\n",
        "print(\"=\" * 70)\n",
        "for layer in model.layers:\n",
        "    if isinstance(layer, layers.Conv2D):\n",
        "        print(f\"Layer Name: {layer.name}\")\n",
        "        print(f\"  Filters: {layer.filters}\")\n",
        "        print(f\"  Kernel Size: {layer.kernel_size}\")\n",
        "        print(f\"  Strides: {layer.strides}\")\n",
        "        print(f\"  Padding: {layer.padding}\")\n",
        "        # Get activation name safely\n",
        "        if hasattr(layer.activation, '__name__'):\n",
        "            activation_name = layer.activation.__name__\n",
        "        elif callable(layer.activation):\n",
        "            activation_name = str(layer.activation)\n",
        "        else:\n",
        "            activation_name = str(layer.activation)\n",
        "        print(f\"  Activation: {activation_name}\")\n",
        "        print(f\"  Input Shape: (28, 28, 1)\")\n",
        "        print(f\"  Output Shape: (26, 26, 32)  [28-3+1=26 with valid padding, 32 filters]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Train the Model\n",
        "\n",
        "Training with 5 epochs, batch size 64, RMSprop optimizer, and sparse categorical crossentropy loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"TRAINING MODEL\")\n",
        "print(\"=\" * 70)\n",
        "print(\"Training with the following settings:\")\n",
        "print(\"  - Epochs: 5\")\n",
        "print(\"  - Batch Size: 64\")\n",
        "print(\"  - Optimizer: RMSprop\")\n",
        "print(\"  - Loss: Sparse Categorical Crossentropy\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=5,\n",
        "                    batch_size=64,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    verbose=1)\n",
        "\n",
        "# Extract final training and validation accuracies\n",
        "final_train_acc = history.history['accuracy'][-1]\n",
        "final_val_acc = history.history['val_accuracy'][-1]\n",
        "\n",
        "# Print per-epoch accuracies\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"TRAINING HISTORY - ACCURACY PER EPOCH\")\n",
        "print(\"=\" * 70)\n",
        "for epoch in range(len(history.history['accuracy'])):\n",
        "    print(f\"Epoch {epoch + 1}:\")\n",
        "    print(f\"  Training Accuracy:   {history.history['accuracy'][epoch]:.4f}\")\n",
        "    print(f\"  Validation Accuracy: {history.history['val_accuracy'][epoch]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Evaluate on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"EVALUATING ON TEST SET\")\n",
        "print(\"=\" * 70)\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Final Results (Formatted for Academic Submission)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"MODEL 1: ORIGINAL CONVOLUTION (TEXTBOOK VERSION)\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Final Training Accuracy:   {final_train_acc:.4f}\")\n",
        "print(f\"Final Validation Accuracy: {final_val_acc:.4f}\")\n",
        "print(f\"Final Test Accuracy:       {test_acc:.4f}\")\n",
        "print(f\"Final Test Loss:           {test_loss:.4f}\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\\nModel Configuration Summary:\")\n",
        "print(\"  - Architecture: Conv2D -> Flatten -> Dense -> Dense\")\n",
        "print(\"  - Conv2D: 32 filters, 3x3 kernel, stride 1, valid padding\")\n",
        "print(\"  - This represents the baseline/original convolution model\")\n",
        "print(\"  - No pooling, no batch normalization, minimal architecture\")\n",
        "print(\"=\" * 70)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
